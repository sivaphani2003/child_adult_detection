{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics opencv-python opencv-python-headless scikit-image\n",
        "!pip install filterpy lap"
      ],
      "metadata": {
        "id": "vKnrCbIWC9jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LkJ2A81nEQQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "video_folder = '/content/drive/MyDrive/vedios'\n",
        "\n",
        "# Iterate over all files in the folder\n",
        "for filename in os.listdir(video_folder):\n",
        "  print(filename)"
      ],
      "metadata": {
        "id": "ZaM9KDEvE_UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "!pip install deep_sort_realtime"
      ],
      "metadata": {
        "id": "99CPYoYoEJWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Load YOLOv8 model (pre-trained)\n",
        "model = YOLO('yolov8l.pt')  # you can use a larger model like yolov8l.pt if needed\n",
        "\n",
        "# Initialize DeepSORT tracker\n",
        "tracker = DeepSort(max_age=50, n_init=2, nn_budget=100)\n",
        "\n",
        "# Define labels for child and adult\n",
        "child_label = \"child\"\n",
        "adult_label = \"therapist\"\n",
        "\n",
        "# Function to detect and track persons\n",
        "def detect_and_track(video_path, output_path):\n",
        "    # Open video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define codec and create VideoWriter object\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detect persons in the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # YOLOv8 provides the detection results, loop through each detection\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            for bbox in result.boxes:\n",
        "                # Bounding box coordinates and confidence score\n",
        "                x1, y1, x2, y2 = bbox.xyxy[0].tolist()\n",
        "                conf = bbox.conf.item()\n",
        "                label_idx = int(bbox.cls.item())  # Get class index\n",
        "\n",
        "                # Filtering out low confidence detections and non-person objects\n",
        "                if label_idx == 0 and conf > 0.7:  # Label 0 corresponds to \"person\"\n",
        "                    # Append bounding box coordinates, confidence, and class label (optional)\n",
        "                    detections.append([[x1, y1, x2, y2], conf])\n",
        "\n",
        "        # Update tracker with detections\n",
        "        tracked_objects = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "        # Draw bounding boxes and labels\n",
        "        for track in tracked_objects:\n",
        "            bbox = track.to_tlbr()  # Bounding box\n",
        "            track_id = track.track_id  # Unique track ID\n",
        "\n",
        "            # Choose label (child or adult) based on some criteria (e.g., bounding box size)\n",
        "            label = child_label if bbox[3] - bbox[1] < 240 else adult_label\n",
        "            if label==child_label:\n",
        "              # Draw bounding box\n",
        "              cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 0, 0), 2)\n",
        "              # Put unique ID and label on the frame\n",
        "              cv2.putText(frame, f\"{label} {track_id}\", (int(bbox[0]), int(bbox[1]) - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "            else:\n",
        "\n",
        "              # Draw bounding box\n",
        "              cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n",
        "              # Put unique ID and label on the frame\n",
        "              cv2.putText(frame, f\"{label} {track_id}\", (int(bbox[0]), int(bbox[1]) - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Write the frame with predictions\n",
        "        out.write(frame)\n",
        "\n",
        "        # Optionally display frame in a window (for debugging)\n",
        "        # cv2.imshow(\"Frame\", frame)\n",
        "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        #     break\n",
        "\n",
        "    # Release everything\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Run detection and tracking on the test video\n",
        "# c=0\n",
        "video_path = '/content/drive/MyDrive/vedios/input2.mp4'\n",
        "output_path = '/content/output2.mp4'\n",
        "detect_and_track(video_path, output_path)\n",
        "\n",
        "# for filename in os.listdir(video_folder):\n",
        "#   # print(filename)\n",
        "#   video_path = '/content/drive/MyDrive/vedios/'+filename\n",
        "#   output_path = '/content/output/output'+str(c)+'.mp4'\n",
        "#   c+=1\n",
        "#   detect_and_track(video_path, output_path)\n"
      ],
      "metadata": {
        "id": "zUB9B-dr_emU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Load YOLOv8 model (pre-trained)\n",
        "model = YOLO('yolov8l.pt')  # you can use a larger model like yolov8l.pt if needed\n",
        "\n",
        "# Initialize DeepSORT tracker\n",
        "tracker = DeepSort(max_age=50, n_init=2, nn_budget=100)\n",
        "\n",
        "# Define labels for child and adult\n",
        "child_label = \"child\"\n",
        "adult_label = \"adult\"\n",
        "\n",
        "# Function to detect and track persons\n",
        "def detect_and_track(video_path, output_path):\n",
        "    # Open video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define codec and create VideoWriter object\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detect persons in the frame\n",
        "        results = model(frame)\n",
        "\n",
        "        # YOLOv8 provides the detection results, loop through each detection\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            for bbox in result.boxes:\n",
        "                # Bounding box coordinates and confidence score\n",
        "                x1, y1, x2, y2 = bbox.xyxy[0].tolist()\n",
        "                conf = bbox.conf.item()\n",
        "                label_idx = int(bbox.cls.item())  # Get class index\n",
        "\n",
        "                # Filtering out low confidence detections and non-person objects\n",
        "                if label_idx == 0 and conf > 0.7:  # Label 0 corresponds to \"person\"\n",
        "                    # Append bounding box coordinates, confidence, and class label (optional)\n",
        "                    detections.append([[x1, y1, x2, y2], conf])\n",
        "\n",
        "        # Update tracker with detections\n",
        "        tracked_objects = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "        # Draw bounding boxes and labels\n",
        "        for track in tracked_objects:\n",
        "            bbox = track.to_tlbr()  # Bounding box\n",
        "            track_id = track.track_id  # Unique track ID\n",
        "\n",
        "            # Choose label (child or adult) based on some criteria (e.g., bounding box size)\n",
        "            label = child_label if bbox[3] - bbox[1] < 240 else adult_label\n",
        "            if label==child_label:\n",
        "              # Draw bounding box\n",
        "              cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 0, 0), 2)\n",
        "              # Put unique ID and label on the frame\n",
        "              cv2.putText(frame, f\"{label} {track_id}\", (int(bbox[0]), int(bbox[1]) - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "            else:\n",
        "\n",
        "              # Draw bounding box\n",
        "              cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n",
        "              # Put unique ID and label on the frame\n",
        "              cv2.putText(frame, f\"{label} {track_id}\", (int(bbox[0]), int(bbox[1]) - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Write the frame with predictions\n",
        "        out.write(frame)\n",
        "\n",
        "        # Optionally display frame in a window (for debugging)\n",
        "        # cv2.imshow(\"Frame\", frame)\n",
        "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        #     break\n",
        "\n",
        "    # Release everything\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Run detection and tracking on the test video\n",
        "# c=0\n",
        "video_path = '/content/drive/MyDrive/vedios/input3.mp4'\n",
        "output_path = '/content/output3.mp4'\n",
        "detect_and_track(video_path, output_path)\n",
        "\n",
        "# for filename in os.listdir(video_folder):\n",
        "#   # print(filename)\n",
        "#   video_path = '/content/drive/MyDrive/vedios/'+filename\n",
        "#   output_path = '/content/output/output'+str(c)+'.mp4'\n",
        "#   c+=1\n",
        "#   detect_and_track(video_path, output_path)\n"
      ],
      "metadata": {
        "id": "EwaBaKdPkpX3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}